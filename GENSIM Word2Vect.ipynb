{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GENSIM Word2Vect.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM13bt/wtgee3qJ+7iL7uMl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"na80RpUrrtVV"},"source":["# https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mo-RUecPr0yY"},"source":["import re  # For preprocessing\n","import pandas as pd  # For data handling\n","from time import time  # To time our operations\n","from collections import defaultdict  # For word frequency\n","\n","import spacy  # For preprocessing\n","\n","import logging  # Setting up the loggings to monitor gensim\n","logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zB51ygNNuedN","executionInfo":{"status":"ok","timestamp":1605189191702,"user_tz":-60,"elapsed":24194,"user":{"displayName":"hyboui CHANG","photoUrl":"","userId":"02436000335260864530"}},"outputId":"dfb43704-76e3-4b5c-9420-141ce3f624e3","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C0HHPGpSvBwc","executionInfo":{"status":"ok","timestamp":1605189400075,"user_tz":-60,"elapsed":709,"user":{"displayName":"hyboui CHANG","photoUrl":"","userId":"02436000335260864530"}},"outputId":"61b849eb-4f45-46ab-ce07-c7b76fe432a1","colab":{"base_uri":"https://localhost:8080/"}},"source":["df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Gensim Word2Vect/simpsons_dataset.csv')\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(158314, 2)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ccgAHA26ufZc","executionInfo":{"status":"ok","timestamp":1605189430717,"user_tz":-60,"elapsed":546,"user":{"displayName":"hyboui CHANG","photoUrl":"","userId":"02436000335260864530"}},"outputId":"a4ec28ff-6c82-48ca-97a9-6517a8702e26","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw_character_text</th>\n","      <th>spoken_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Miss Hoover</td>\n","      <td>No, actually, it was a little of both. Sometim...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lisa Simpson</td>\n","      <td>Where's Mr. Bergstrom?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Miss Hoover</td>\n","      <td>I don't know. Although I'd sure like to talk t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Lisa Simpson</td>\n","      <td>That life is worth living.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Edna Krabappel-Flanders</td>\n","      <td>The polls will be open from now until the end ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        raw_character_text                                       spoken_words\n","0              Miss Hoover  No, actually, it was a little of both. Sometim...\n","1             Lisa Simpson                             Where's Mr. Bergstrom?\n","2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n","3             Lisa Simpson                         That life is worth living.\n","4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"e2j04LuxufRM","executionInfo":{"status":"ok","timestamp":1605189456843,"user_tz":-60,"elapsed":624,"user":{"displayName":"hyboui CHANG","photoUrl":"","userId":"02436000335260864530"}},"outputId":"0d366bb5-7db2-4618-bbe5-fd70165eeae2","colab":{"base_uri":"https://localhost:8080/"}},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["raw_character_text    17814\n","spoken_words          26459\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"b4P4QHwmufFq","executionInfo":{"status":"ok","timestamp":1605189817686,"user_tz":-60,"elapsed":515,"user":{"displayName":"hyboui CHANG","photoUrl":"","userId":"02436000335260864530"}},"outputId":"108316da-e65e-49d3-e9c9-4aad8b306138","colab":{"base_uri":"https://localhost:8080/"}},"source":["df = df.dropna().reset_index(drop=True)\n","df.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO - 14:03:35: NumExpr defaulting to 2 threads.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["raw_character_text    0\n","spoken_words          0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"FhwNFdn_v4ua"},"source":["# We are lemmatizing (ex jouera == jouer) and removing the stopwords (les mots vides) and non-alphabetic characters for each line of dialogue\n","\n","nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n","\n","def cleaning(doc):\n","    # Lemmatizes and removes stopwords\n","    # doc needs to be a spacy Doc object\n","    txt = [token.lemma_ for token in doc if not token.is_stop]\n","    # Word2Vec uses context words to learn the vector representation of a target word,\n","    # if a sentence is only one or two words long,\n","    # the benefit for the training is very small\n","    if len(txt) > 2:\n","        return ' '.join(txt)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1R-23bkv5PZ"},"source":["# Removes non-alphabetic characters\n","\n","brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPUcaCcdv5dI"},"source":["# Taking advantage of spaCy .pipe() attribute to speed-up the cleaning process:\n","\n","t = time()\n","\n","txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n","\n","print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xc9VC3Sjv5nS"},"source":["# Put the results in a DataFrame to remove missing values and duplicates\n","\n","df_clean = pd.DataFrame({'clean': txt})\n","df_clean = df_clean.dropna().drop_duplicates()\n","df_clean.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIoLy0_3v5xZ"},"source":["# Bigrams:\n","# We are using Gensim Phrases package to automatically detect common phrases (bigrams) from a list of sentences. \n","# https://radimrehurek.com/gensim/models/phrases.html\n","\n","from gensim.models.phrases import Phrases, Phraser\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCXF5MCbv57R"},"source":["# As Phrases() takes a list of list of words as input:\n","\n","sent = [row.split() for row in df_clean['clean']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsy87X58v6ER"},"source":["# Creates the relevant phrases from the list of sentences\n","\n","phrases = Phrases(sent, min_count=30, progress_per=10000)\n","\n"],"execution_count":null,"outputs":[]}]}